---
title: Agent èŠç€èŠç€å°±å¿˜äº†ï¼Ÿè®°å¿†ç®¡ç†å¦‚ä½•çªç ´ Context Window
date: 2025-12-17 18:00:00
updated: {{current_date_time}}
categories:
  - ğŸ§  LLM/Agent ä»å…¥é—¨åˆ°ç²¾é€šï¼šå‘Šåˆ«æµ…å°è¾„æ­¢
  - AIä¸ç ”ç©¶
tags:
  - LLM
  - Agent
  - Memory
  - Context Window
  - è®°å¿†ç®¡ç†
  - å‘é‡æ•°æ®åº“
keywords: LLM, Agent, Memory, Context Window, è®°å¿†ç®¡ç†, STM, LTM, çŸ­æœŸè®°å¿†, é•¿æœŸè®°å¿†, å‘é‡æ•°æ®åº“, çŸ¥è¯†å›¾è°±
description: 'æ·±å…¥è§£æ Agent çš„è®°å¿†ç®¡ç†ï¼šä»åˆ†å±‚è®°å¿†æ¶æ„ã€çŸ­æœŸè®°å¿†ç®¡ç†ç­–ç•¥åˆ°é•¿æœŸè®°å¿†å­˜å‚¨æ£€ç´¢ï¼Œæ‰“é€ é•¿æœŸä¸”å¥å¿˜çš„æ™ºèƒ½ä½“ç³»ç»Ÿ'
top_img: /img/llm-agent-memory-management.png
cover: /img/llm-agent-memory-management.png
comments: true
toc: true
toc_number: true
toc_style_simple: false
copyright: true
copyright_author: yuxiaoling
copyright_info: ç‰ˆæƒæ‰€æœ‰ï¼Œè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚
mathjax: true
katex: false
aplayer: false
highlight_shrink: false
aside: true
noticeOutdate: false
---

Agent å¤šè½®å¯¹è¯åï¼Œå‰é¢çš„å…³é”®ä¿¡æ¯è¢«"æŒ¤"å‡º Context Windowï¼Œå¼€å§‹ç­”éæ‰€é—®ã€‚**å¦‚ä½•è®© Agent è®°ä½é‡è¦ä¿¡æ¯ã€å¿˜è®°æ— å…³ä¿¡æ¯ï¼Ÿ**

è®°å¿†ç®¡ç†é€šè¿‡çŸ­æœŸè®°å¿†ï¼ˆSTMï¼‰ã€é•¿æœŸè®°å¿†ï¼ˆLTMï¼‰ã€å‘é‡åº“ç­‰åˆ†å±‚æ¶æ„ï¼Œçªç ´ Context Window é™åˆ¶ã€‚æœ¬ç¯‡è§£æå¦‚ä½•è®¾è®¡"è¯¥è®°çš„è®°ã€è¯¥å¿˜çš„å¿˜"çš„è®°å¿†ç³»ç»Ÿã€‚

**è®°å¿†ç®¡ç†** = è¯¥è®°çš„è®°ï¼ˆé‡è¦ä¿¡æ¯å­˜ LTMï¼‰ã€è¯¥å¿˜çš„å¿˜ï¼ˆå‹ç¼©/å‰ªæï¼‰ã€è¯¥æŸ¥çš„æŸ¥ï¼ˆéœ€è¦æ—¶ä»çŸ¥è¯†åº“æ£€ç´¢ï¼‰ã€‚Context Window æœ‰é™ã€æˆæœ¬é«˜ã€å…¨å¡è¿›å»ä¼šæ‹–æ…¢æ¨ç†â€”â€”åˆ†å±‚æ¶æ„ï¼ˆSTM + LTM + ExMï¼‰è§£å†³è¿™ä¸‰ä¸ªé—®é¢˜ã€‚

---

## ğŸ§  ä¸€ã€Agent çš„åˆ†å±‚è®°å¿†æ¶æ„

Agent ç»„æˆä¸è®°å¿†åœ¨æ•´ä½“æ¶æ„ä¸­çš„ä½ç½®è¯¦è§[ç¬¬ 6 ç¯‡](/2025-12-10-llm-agent-concept-overview/)ã€‚æœ¬ç¯‡æ·±å…¥è§£æè®°å¿†çš„åˆ†å±‚æ¶æ„ã€‚åƒäººè„‘ï¼š**çŸ­æœŸ**è®°å½“å‰åœ¨åšçš„äº‹ï¼Œ**é•¿æœŸ**å­˜é‡è¦ç»å†ï¼Œ**å¤–éƒ¨**éœ€è¦æ—¶æŸ¥èµ„æ–™ã€‚Agent åŒç†ï¼š
- **çŸ­æœŸè®°å¿†ï¼ˆSTMï¼‰**ï¼šè®°ä½å½“å‰å¯¹è¯å’Œä»»åŠ¡çš„å…³é”®ä¿¡æ¯
- **é•¿æœŸè®°å¿†ï¼ˆLTMï¼‰**ï¼šä¿å­˜å†å²ç»éªŒå’Œç”¨æˆ·åå¥½
- **å¤–éƒ¨çŸ¥è¯†ï¼ˆExMï¼‰**ï¼šéœ€è¦æ—¶ä»çŸ¥è¯†åº“æ£€ç´¢

### 1.1 ä¸‰å±‚è®°å¿†æ¶æ„è¯¦è§£

| å±‚æ¬¡ | æ¦‚å¿µæ¯”å–» | å­˜å‚¨ä»‹è´¨ | å†…å®¹ä¸åŠŸèƒ½ | æ ¸å¿ƒæŒ‘æˆ˜ | ç®€å•ç†è§£ |
|------|---------|---------|-----------|---------|---------|
| **çŸ­æœŸè®°å¿† (STM)** | **å¤§è„‘ RAM** | Context Window (Prompt) | å½“å‰ä¼šè¯çš„ Thought / Action / Observation åºåˆ—ï¼Œç¡®ä¿ä»»åŠ¡è¿è´¯æ€§ | **Token é•¿åº¦é™åˆ¶**ï¼šå®¹æ˜“æº¢å‡º | è®°ä½å½“å‰æ­£åœ¨åšçš„äº‹æƒ… |
| **é•¿æœŸè®°å¿† (LTM)** | **ç¡¬ç›˜ Hard Drive** | å‘é‡æ•°æ®åº“ / çŸ¥è¯†å›¾è°± | å†å²ç»éªŒã€ç”¨æˆ·åå¥½ã€é¡¹ç›®è¿›åº¦æ‘˜è¦ | **é«˜æ•ˆæ£€ç´¢**ï¼šå¦‚ä½•å¬å›ç›¸å…³ä¿¡æ¯ | ä¿å­˜è¿‡å»çš„é‡è¦ç»å† |
| **å¤–éƒ¨çŸ¥è¯† (ExM)** | **ç™¾ç§‘å…¨ä¹¦** | RAG çŸ¥è¯†åº“ / API æ•°æ® | äº‹å®æ€§ã€ä¸“ä¸šæ€§ã€éä¸ªäººåŒ–ä¿¡æ¯ | **çŸ¥è¯†æ—¶æ•ˆæ€§**ï¼šéœ€è¦å®šæœŸæ›´æ–° | éœ€è¦æ—¶æŸ¥é˜…èµ„æ–™ |

### 1.2 ç”Ÿæ´»åŒ–ç†è§£ï¼šä¸‰å±‚è®°å¿†å¦‚ä½•å·¥ä½œ

**åœºæ™¯**ï¼šå®¢æœ Agent å¤„ç†å¤šè½®å’¨è¯¢â€”â€”ç”¨æˆ·å…ˆé—®é€€æ¢è´§æ”¿ç­–ï¼Œå†é—®æŸè®¢å•çŠ¶æ€ï¼Œæœ€åè¦æ±‚é€€æ¬¾ã€‚Agent éœ€è¦è®°ä½å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆSTMï¼‰ã€ç”¨æˆ·å†å²åå¥½ï¼ˆLTMï¼‰ã€æ”¿ç­–æ–‡æ¡£ï¼ˆExMï¼‰ã€‚

**çŸ­æœŸè®°å¿†ï¼ˆSTMï¼‰**ï¼š
> è®°ä½å½“å‰ä»»åŠ¡çš„å…³é”®ä¿¡æ¯ï¼š
> - "æˆ‘æ­£åœ¨æŸ¥è¯¢ç”¨æˆ·æ•°æ®"
> - "æŸ¥è¯¢æˆåŠŸï¼Œè¿”å›äº† 1000 æ¡è®°å½•"
> - "ç°åœ¨éœ€è¦ç”ŸæˆæŠ¥å‘Š"
> 
> å°±åƒä½ æ­£åœ¨çœ‹ä¹¦æ—¶ï¼Œè®°ä½å½“å‰é¡µçš„å†…å®¹ã€‚

**é•¿æœŸè®°å¿†ï¼ˆLTMï¼‰**ï¼š
> ä¿å­˜é‡è¦çš„å†å²ä¿¡æ¯ï¼š
> - "ç”¨æˆ·åå¥½ï¼šå–œæ¬¢ PDF æ ¼å¼çš„æŠ¥å‘Š"
> - "ä¸Šæ¬¡æŸ¥è¯¢æ—¶é‡åˆ°äº†æ•°æ®åº“è¿æ¥é—®é¢˜"
> - "é¡¹ç›®è¿›åº¦ï¼šå·²å®Œæˆ 80%"
> 
> å°±åƒä½ è®°ä½è¿‡å»å­¦è¿‡çš„çŸ¥è¯†ã€‚

**å¤–éƒ¨çŸ¥è¯†ï¼ˆExMï¼‰**ï¼š
> éœ€è¦æ—¶ä»çŸ¥è¯†åº“æ£€ç´¢ï¼š
> - "æ•°æ®åº“æŸ¥è¯¢çš„æœ€ä½³å®è·µ"
> - "æŠ¥å‘Šç”Ÿæˆçš„æ¨¡æ¿"
> - "API æ–‡æ¡£"
> 
> å°±åƒä½ æŸ¥å­—å…¸æˆ–æŸ¥ç™¾ç§‘ã€‚

### 1.3 ä¸‰å±‚è®°å¿†å¦‚ä½•åä½œ

**å·¥ä½œæµç¨‹**ï¼š

```
1. ç”¨æˆ·è¾“å…¥ä»»åŠ¡
   â†“
2. ä» LTM æ£€ç´¢ç›¸å…³å†å²ä¿¡æ¯ï¼ˆç”¨æˆ·åå¥½ã€å†å²ç»éªŒï¼‰
   â†“
3. ä» ExM æ£€ç´¢ç›¸å…³çŸ¥è¯†ï¼ˆAPI æ–‡æ¡£ã€æœ€ä½³å®è·µï¼‰
   â†“
4. æŠŠæ£€ç´¢åˆ°çš„ä¿¡æ¯ + å½“å‰ä»»åŠ¡æ”¾å…¥ STMï¼ˆContext Windowï¼‰
   â†“
5. LLM åŸºäº STM è¿›è¡Œæ¨ç†å’Œå†³ç­–
   â†“
6. æŠŠé‡è¦ä¿¡æ¯ä¿å­˜åˆ° LTMï¼ˆé•¿æœŸè®°å¿†ï¼‰
   â†“
7. ç»§ç»­ä¸‹ä¸€è½®å¾ªç¯
```

> ğŸ’¡ **å…³é”®ç†è§£**ï¼š
> - **STM**ï¼šä¿è¯å½“å‰ä»»åŠ¡çš„å³æ—¶è¿è´¯ï¼ˆå°±åƒå·¥ä½œè®°å¿†ï¼‰
> - **LTM**ï¼šæŒä¹…åŒ–ç»éªŒï¼Œæ”¯æŒè·¨ä»»åŠ¡å­¦ä¹ ï¼ˆå°±åƒé•¿æœŸè®°å¿†ï¼‰
> - **ExM**ï¼šæä¾›äº‹å®æ€§ä¸ä¸“ä¸šçŸ¥è¯†ï¼ˆå°±åƒæŸ¥é˜…èµ„æ–™ï¼‰
> 
> ä¸‰è€…ç»“åˆï¼Œç¡®ä¿ Agent æ—¢èƒ½è®°ä½é‡è¦ä¿¡æ¯ï¼Œåˆèƒ½æ™ºèƒ½é—å¿˜ä¸é‡è¦çš„ç»†èŠ‚ã€‚

---

## ğŸ’¾ äºŒã€çŸ­æœŸè®°å¿† (STM) çš„ç®¡ç†ç­–ç•¥

Context Window æœ‰é™ï¼Œå†™æ»¡äº†å°±è¦æ“¦â€”â€”**æ“¦å“ªäº›ï¼Ÿç•™å“ªäº›ï¼Ÿ** ä¸‰ç§ç­–ç•¥ï¼šæ»‘åŠ¨çª—å£ï¼ˆåªç•™æœ€è¿‘ N è½®ï¼‰ã€å¯¹è¯æ‘˜è¦ï¼ˆå‹ç¼©æˆæ‘˜è¦ï¼‰ã€é‡è¦æ€§å‰ªæï¼ˆåªç•™å…³é”®ä¿¡æ¯ï¼‰ã€‚

### 2.1 Sliding Windowï¼ˆæ»‘åŠ¨çª—å£ï¼‰

åªä¿ç•™æœ€è¿‘ N è½®ï¼Œæ—§çš„è‡ªåŠ¨ä¸¢å¼ƒã€‚ç®€å•ç²—æš´ï¼Œä½†å¯èƒ½ä¸¢æ‰å…³é”®ä¿¡æ¯ã€‚

**æœºåˆ¶**ï¼š
> ä¿ç•™æœ€è¿‘ N è½® Thought / Action / Observationï¼Œæ—§ä¿¡æ¯è¢«ä¸¢å¼ƒæˆ–è¿ç§»åˆ° LTM

**ç”Ÿæ´»ä¾‹å­**ï¼š
> å°±åƒä½ çš„æ‰‹æœºé€šçŸ¥æ ï¼š
> - åªæ˜¾ç¤ºæœ€è¿‘ 10 æ¡é€šçŸ¥
> - æ–°çš„é€šçŸ¥æ¥äº†ï¼Œæœ€æ—§çš„é€šçŸ¥è¢«æŒ¤æ‰
> - ç®€å•ç›´æ¥ï¼Œä½†å¯èƒ½ä¸¢å¤±é‡è¦ä¿¡æ¯

**é€‚ç”¨åœºæ™¯**ï¼š
> - å¯¹è¯è½®æ¬¡æœ‰é™
> - ä»»åŠ¡æ­¥éª¤æ˜ç¡®
> - ä¸éœ€è¦é•¿æœŸä¸Šä¸‹æ–‡

**ä»£ç ç¤ºä¾‹**ï¼š

```python
# æ»‘åŠ¨çª—å£ï¼ˆä¼ªä»£ç ï¼‰

class SlidingWindowMemory:
    def __init__(self, max_size=10):
        self.max_size = max_size  # æœ€å¤šä¿ç•™ 10 è½®å¯¹è¯
        self.memories = []  # è®°å¿†åˆ—è¡¨
    
    def add(self, thought, action, observation):
        """æ·»åŠ æ–°çš„è®°å¿†"""
        memory = {
            "thought": thought,
            "action": action,
            "observation": observation
        }
        self.memories.append(memory)
        
        # å¦‚æœè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œåˆ é™¤æœ€æ—§çš„
        if len(self.memories) > self.max_size:
            old_memory = self.memories.pop(0)  # åˆ é™¤æœ€æ—§çš„
            # å¯é€‰ï¼šæŠŠæ—§è®°å¿†è¿ç§»åˆ° LTM
            # self.save_to_ltm(old_memory)
    
    def get_context(self):
        """è·å–å½“å‰ä¸Šä¸‹æ–‡"""
        return self.memories

# ä½¿ç”¨ç¤ºä¾‹
memory = SlidingWindowMemory(max_size=5)

# æ·»åŠ è®°å¿†
memory.add("æ€è€ƒ1", "è¡ŒåŠ¨1", "è§‚å¯Ÿ1")
memory.add("æ€è€ƒ2", "è¡ŒåŠ¨2", "è§‚å¯Ÿ2")
# ... ç»§ç»­æ·»åŠ 

# å½“è¶…è¿‡ 5 è½®æ—¶ï¼Œæœ€æ—§çš„ä¼šè¢«è‡ªåŠ¨åˆ é™¤
```

### 2.2 Conversational Summarizationï¼ˆå¯¹è¯æ‘˜è¦ï¼‰

LLM å®šæœŸæŠŠæœ€æ—§å†…å®¹æ‘˜è¦æˆçŸ­æ–‡æœ¬ï¼Œä¿ç•™å…³é”®ä¿¡æ¯â€”â€”åƒè¯»ä¹¦ç¬”è®°ï¼Œè®°ç»“è®ºä¸è®°å…¨æ–‡ã€‚ä»·å€¼ï¼š
> - èŠ‚çœ Token ç©ºé—´
> - ä¿ç•™å…³é”®ä¸»é¢˜å’Œç»“è®º
> - ä¸ä¼šä¸¢å¤±é‡è¦ä¿¡æ¯

**å·¥ç¨‹å®ç°**ï¼š
> æ¯ K è½®å¾ªç¯è°ƒç”¨ **Summarizer LLM**ï¼Œç”Ÿæˆæ›´æ–°åçš„è®°å¿†ç‰‡æ®µ

**ä»£ç ç¤ºä¾‹**ï¼š

```python
# å¯¹è¯æ‘˜è¦ï¼ˆä¼ªä»£ç ï¼‰

class SummarizedMemory:
    def __init__(self, summarizer_llm, summary_interval=5):
        self.summarizer_llm = summarizer_llm
        self.summary_interval = summary_interval  # æ¯ 5 è½®æ‘˜è¦ä¸€æ¬¡
        self.memories = []
        self.summary = ""  # ä¿å­˜æ‘˜è¦
    
    def add(self, thought, action, observation):
        """æ·»åŠ æ–°çš„è®°å¿†"""
        memory = {
            "thought": thought,
            "action": action,
            "observation": observation
        }
        self.memories.append(memory)
        
        # æ¯ N è½®è¿›è¡Œä¸€æ¬¡æ‘˜è¦
        if len(self.memories) >= self.summary_interval:
            self.summarize()
    
    def summarize(self):
        """å¯¹æ—§è®°å¿†è¿›è¡Œæ‘˜è¦"""
        # è·å–éœ€è¦æ‘˜è¦çš„è®°å¿†ï¼ˆæœ€æ—§çš„éƒ¨åˆ†ï¼‰
        old_memories = self.memories[:self.summary_interval]
        
        # æ„å»ºæ‘˜è¦ Prompt
        prompt = f"""
        è¯·å¯¹ä»¥ä¸‹å¯¹è¯è¿›è¡Œæ‘˜è¦ï¼Œä¿ç•™å…³é”®ä¿¡æ¯å’Œç»“è®ºï¼š
        
        {format_memories(old_memories)}
        
        æ‘˜è¦ï¼š
        """
        
        # è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
        new_summary = self.summarizer_llm.generate(prompt)
        
        # æ›´æ–°æ‘˜è¦ï¼ˆåˆå¹¶æ–°æ—§æ‘˜è¦ï¼‰
        self.summary = self.summary + "\n" + new_summary
        
        # åˆ é™¤å·²æ‘˜è¦çš„è®°å¿†
        self.memories = self.memories[self.summary_interval:]
    
    def get_context(self):
        """è·å–å½“å‰ä¸Šä¸‹æ–‡ï¼ˆæ‘˜è¦ + æœ€è¿‘è®°å¿†ï¼‰"""
        return {
            "summary": self.summary,
            "recent_memories": self.memories
        }

# ä½¿ç”¨ç¤ºä¾‹
memory = SummarizedMemory(summarizer_llm=gpt4, summary_interval=5)

# æ·»åŠ è®°å¿†
for i in range(10):
    memory.add(f"æ€è€ƒ{i}", f"è¡ŒåŠ¨{i}", f"è§‚å¯Ÿ{i}")
    # ç¬¬ 5 è½®å’Œç¬¬ 10 è½®ä¼šè‡ªåŠ¨è§¦å‘æ‘˜è¦
```

### 2.3 Importance-Based Pruningï¼ˆåŸºäºé‡è¦æ€§çš„å‰ªæï¼‰

ä¸ºæ¯æ®µè®°å¿†æ‰“**é‡è¦æ€§å¾—åˆ†**ï¼ŒContext æ»¡è½½æ—¶ä¼˜å…ˆç§»é™¤ä½åˆ†â€”â€”åƒæ‰‹æœºç›¸å†Œï¼Œç©ºé—´ä¸è¶³æ—¶å…ˆåˆ æˆªå›¾ã€‚è¯„åˆ†æ–¹å¼ï¼š
> é€šè¿‡å°å‹åˆ†ç±»æ¨¡å‹æˆ– LLM Promptï¼Œæ ¹æ®ä¸æ ¸å¿ƒä»»åŠ¡ç›®æ ‡çš„å…³è”æ€§è¯„åˆ†

**ä»£ç ç¤ºä¾‹**ï¼š

```python
# åŸºäºé‡è¦æ€§çš„å‰ªæï¼ˆä¼ªä»£ç ï¼‰

class ImportanceBasedMemory:
    def __init__(self, max_tokens=10000, importance_scorer=None):
        self.max_tokens = max_tokens
        self.importance_scorer = importance_scorer  # é‡è¦æ€§è¯„åˆ†å™¨
        self.memories = []
    
    def add(self, thought, action, observation, task_goal=None):
        """æ·»åŠ æ–°çš„è®°å¿†ï¼Œå¹¶è®¡ç®—é‡è¦æ€§"""
        memory = {
            "thought": thought,
            "action": action,
            "observation": observation,
            "importance": self.score_importance(thought, action, observation, task_goal)
        }
        self.memories.append(memory)
        
        # å¦‚æœè¶…è¿‡ Token é™åˆ¶ï¼Œè¿›è¡Œå‰ªæ
        if self.get_total_tokens() > self.max_tokens:
            self.prune()
    
    def score_importance(self, thought, action, observation, task_goal):
        """è®¡ç®—è®°å¿†çš„é‡è¦æ€§å¾—åˆ†ï¼ˆ0-1ï¼‰"""
        if self.importance_scorer:
            # ä½¿ç”¨å¤–éƒ¨è¯„åˆ†å™¨
            return self.importance_scorer.score(thought, action, observation, task_goal)
        else:
            # ç®€å•çš„å¯å‘å¼è¯„åˆ†ï¼ˆå®é™…åº”è¯¥ç”¨ LLM æˆ–æ¨¡å‹ï¼‰
            # ä¾‹å¦‚ï¼šåŒ…å«"é”™è¯¯"ã€"å¤±è´¥"çš„è®°å¿†é‡è¦æ€§æ›´é«˜
            if "é”™è¯¯" in observation or "å¤±è´¥" in observation:
                return 0.9
            elif "æˆåŠŸ" in observation:
                return 0.7
            else:
                return 0.5
    
    def prune(self):
        """å‰ªæï¼šç§»é™¤ä½é‡è¦æ€§è®°å¿†"""
        # æŒ‰é‡è¦æ€§æ’åº
        self.memories.sort(key=lambda x: x["importance"], reverse=True)
        
        # ç§»é™¤ä½é‡è¦æ€§è®°å¿†ï¼Œç›´åˆ°æ»¡è¶³ Token é™åˆ¶
        while self.get_total_tokens() > self.max_tokens:
            if len(self.memories) > 0:
                removed = self.memories.pop()  # ç§»é™¤æœ€ä½é‡è¦æ€§è®°å¿†
                # å¯é€‰ï¼šä¿å­˜åˆ° LTM
                # self.save_to_ltm(removed)
            else:
                break
    
    def get_total_tokens(self):
        """è®¡ç®—æ€» Token æ•°"""
        total = 0
        for memory in self.memories:
            total += count_tokens(memory["thought"])
            total += count_tokens(memory["action"])
            total += count_tokens(memory["observation"])
        return total
    
    def get_context(self):
        """è·å–å½“å‰ä¸Šä¸‹æ–‡ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰"""
        return sorted(self.memories, key=lambda x: x["importance"], reverse=True)

# ä½¿ç”¨ç¤ºä¾‹
memory = ImportanceBasedMemory(max_tokens=10000)

# æ·»åŠ è®°å¿†
memory.add("æ€è€ƒ1", "è¡ŒåŠ¨1", "è§‚å¯Ÿ1ï¼šæŸ¥è¯¢æˆåŠŸ", task_goal="æŸ¥è¯¢æ•°æ®")
memory.add("æ€è€ƒ2", "è¡ŒåŠ¨2", "è§‚å¯Ÿ2ï¼šæŸ¥è¯¢å¤±è´¥ï¼Œæ•°æ®åº“è¿æ¥é”™è¯¯", task_goal="æŸ¥è¯¢æ•°æ®")
# ç¬¬äºŒä¸ªè®°å¿†çš„é‡è¦æ€§æ›´é«˜ï¼ˆåŒ…å«"é”™è¯¯"ï¼‰ï¼Œä¼šè¢«ä¼˜å…ˆä¿ç•™
```

### 2.4 ä¸‰ç§ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|---------|
| **æ»‘åŠ¨çª—å£** | ç®€å•ç›´æ¥ï¼Œå®ç°å®¹æ˜“ | å¯èƒ½ä¸¢å¤±é‡è¦ä¿¡æ¯ | å¯¹è¯è½®æ¬¡æœ‰é™ï¼Œä»»åŠ¡ç®€å• |
| **å¯¹è¯æ‘˜è¦** | ä¿ç•™å…³é”®ä¿¡æ¯ï¼ŒèŠ‚çœç©ºé—´ | éœ€è¦é¢å¤–çš„ LLM è°ƒç”¨ï¼Œæˆæœ¬è¾ƒé«˜ | éœ€è¦é•¿æœŸä¸Šä¸‹æ–‡ï¼Œä»»åŠ¡å¤æ‚ |
| **é‡è¦æ€§å‰ªæ** | æ™ºèƒ½é€‰æ‹©ï¼Œä¿ç•™é‡è¦ä¿¡æ¯ | è¯„åˆ†å‡†ç¡®æ€§ä¾èµ–æ¨¡å‹ | éœ€è¦åŒºåˆ†é‡è¦/ä¸é‡è¦ä¿¡æ¯ |

**é€‰æ‹©æŒ‡å—**ï¼š
- âœ… **ç®€å•ä»»åŠ¡**ï¼šä½¿ç”¨æ»‘åŠ¨çª—å£
- âœ… **éœ€è¦é•¿æœŸä¸Šä¸‹æ–‡**ï¼šä½¿ç”¨å¯¹è¯æ‘˜è¦
- âœ… **éœ€è¦æ™ºèƒ½é€‰æ‹©**ï¼šä½¿ç”¨é‡è¦æ€§å‰ªæ
- âœ… **æœ€ä½³å®è·µ**ï¼šç»“åˆä½¿ç”¨ï¼ˆå¦‚ï¼šæ»‘åŠ¨çª—å£ + é‡è¦æ€§å‰ªæï¼‰

---

## ğŸ—„ï¸ ä¸‰ã€é•¿æœŸè®°å¿† (LTM) çš„å­˜å‚¨ä¸æ£€ç´¢

LTM æŒä¹…åŒ–ç»éªŒä¸ç”¨æˆ·ç”»åƒï¼Œæ ¸å¿ƒæ˜¯**é«˜æ•ˆæ£€ç´¢**â€”â€”åƒç¡¬ç›˜ï¼Œå­˜å¾—å¤šä½†è¦èƒ½å¿«é€Ÿæ‰¾åˆ°ã€‚

### 3.1 å­˜å‚¨ä»‹è´¨å¤šæ ·æ€§

**ä¸‰ç§å­˜å‚¨æ–¹å¼ï¼Œå„æœ‰ä¼˜åŠ¿**ï¼š

#### 1. å‘é‡æ•°æ®åº“ (Vector Stores)

**ç®€å•ç†è§£**ï¼šå°±åƒæœç´¢å¼•æ“ï¼Œé€šè¿‡"è¯­ä¹‰ç›¸ä¼¼æ€§"æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚

**å­˜å‚¨å†…å®¹**ï¼š
 - å†å²å¯¹è¯
 - Observationï¼ˆè§‚å¯Ÿç»“æœï¼‰
 - Thoughtï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰

**æ£€ç´¢æ–¹å¼**ï¼šè¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢ï¼ˆRAG åŸºç¡€ï¼‰
 - æŠŠæŸ¥è¯¢è½¬æ¢æˆå‘é‡
 - åœ¨å‘é‡ç©ºé—´ä¸­æ‰¾æœ€ç›¸ä¼¼çš„è®°å¿†
 - å°±åƒ"æ‰¾ç›¸ä¼¼çš„æ–‡ç« "

**é€‚ç”¨åœºæ™¯**ï¼š
 - éœ€è¦è¯­ä¹‰æ£€ç´¢ï¼ˆå¦‚"æ‰¾ç›¸å…³çš„å†å²å¯¹è¯"ï¼‰
 - éç»“æ„åŒ–æ•°æ®ï¼ˆæ–‡æœ¬ã€å¯¹è¯ï¼‰

**å¸¸è§å·¥å…·**ï¼š
 - Pineconeã€Weaviateã€Qdrantã€Chroma

 ---

#### 2. çŸ¥è¯†å›¾è°± (Knowledge Graphs)

**ç®€å•ç†è§£**ï¼š å°±åƒå…³ç³»æ•°æ®åº“ï¼Œå­˜å‚¨å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚

**å­˜å‚¨å†…å®¹**ï¼š
 - ç»“æ„åŒ–å…³ç³»ï¼ˆå¦‚ç”¨æˆ·åå¥½ä¸é¡¹ç›®å…³è”ï¼‰
 - å®ä½“å’Œå…³ç³»ï¼ˆå¦‚"ç”¨æˆ·A å–œæ¬¢ é¡¹ç›®B"ï¼‰

**æ£€ç´¢æ–¹å¼**ï¼š å¤šè·³æ¨ç†ï¼ˆCypher / SPARQLï¼‰
 - é€šè¿‡å…³ç³»é“¾æ‰¾åˆ°ç›¸å…³ä¿¡æ¯
 - å°±åƒ"æ‰¾æœ‹å‹çš„æœ‹å‹"

**é€‚ç”¨åœºæ™¯**ï¼š
 - éœ€è¦å…³ç³»æ¨ç†ï¼ˆå¦‚"æ‰¾ç”¨æˆ·å–œæ¬¢çš„é¡¹ç›®"ï¼‰
 - ç»“æ„åŒ–æ•°æ®ï¼ˆå®ä½“ã€å…³ç³»ï¼‰

**å¸¸è§å·¥å…·**ï¼š
 - Neo4jã€ArangoDB

 ---

#### 3. Key-Value / å…³ç³»å‹æ•°æ®åº“ (SQL/NoSQL)

**ç®€å•ç†è§£**ï¼š å°±åƒä¼ ç»Ÿçš„æ•°æ®åº“ï¼Œé€šè¿‡é”®å€¼æˆ– SQL æŸ¥è¯¢ã€‚

**å­˜å‚¨å†…å®¹**ï¼š
 - ç”¨æˆ·é…ç½®
 - é¡¹ç›®çŠ¶æ€
 - ä»»åŠ¡æ¸…å•

**æ£€ç´¢æ–¹å¼**ï¼š Function Calling æˆ– Text-to-SQL
 - é€šè¿‡é”®å€¼æŸ¥è¯¢
 - æˆ–é€šè¿‡ SQL æŸ¥è¯¢

**é€‚ç”¨åœºæ™¯**ï¼š
 - éœ€è¦ç²¾ç¡®æŸ¥è¯¢ï¼ˆå¦‚"æŸ¥è¯¢ç”¨æˆ·ID=123çš„é…ç½®"ï¼‰
 - ç»“æ„åŒ–æ•°æ®ï¼ˆè¡¨ã€å­—æ®µï¼‰

**å¸¸è§å·¥å…·**ï¼š
 - PostgreSQLã€MySQLã€MongoDBã€Redis

### 3.2 å­˜å‚¨ä»‹è´¨é€‰æ‹©æŒ‡å—

| å­˜å‚¨ä»‹è´¨ | æ£€ç´¢æ–¹å¼ | é€‚ç”¨åœºæ™¯ | ç®€å•ç†è§£ |
|---------|---------|---------|---------|
| **å‘é‡æ•°æ®åº“** | è¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢ | éç»“æ„åŒ–æ–‡æœ¬ã€å¯¹è¯å†å² | åƒæœç´¢å¼•æ“ï¼Œæ‰¾ç›¸ä¼¼å†…å®¹ |
| **çŸ¥è¯†å›¾è°±** | å…³ç³»æ¨ç† | ç»“æ„åŒ–å…³ç³»ã€å®ä½“å…³è” | åƒå…³ç³»æ•°æ®åº“ï¼Œæ‰¾å…³è”ä¿¡æ¯ |
| **å…³ç³»å‹æ•°æ®åº“** | SQL/é”®å€¼æŸ¥è¯¢ | ç»“æ„åŒ–æ•°æ®ã€ç²¾ç¡®æŸ¥è¯¢ | åƒä¼ ç»Ÿæ•°æ®åº“ï¼Œç²¾ç¡®æŸ¥æ‰¾ |

**é€‰æ‹©æŒ‡å—**ï¼š
- âœ… **æ–‡æœ¬ã€å¯¹è¯**ï¼šä½¿ç”¨å‘é‡æ•°æ®åº“
- âœ… **å…³ç³»ã€å®ä½“**ï¼šä½¿ç”¨çŸ¥è¯†å›¾è°±
- âœ… **é…ç½®ã€çŠ¶æ€**ï¼šä½¿ç”¨å…³ç³»å‹æ•°æ®åº“
- âœ… **æœ€ä½³å®è·µ**ï¼šç»“åˆä½¿ç”¨ï¼ˆå¦‚ï¼šå‘é‡æ•°æ®åº“ + å…³ç³»å‹æ•°æ®åº“ï¼‰

### 3.3 é«˜çº§æ£€ç´¢ç­–ç•¥ï¼šContextual Memory Retrieval

ä¸åªæ‰¾"ç›¸ä¼¼"ï¼Œè¿˜è¦è€ƒè™‘**ç›¸ä¼¼æ€§**ï¼ˆæ˜¯å¦ç›¸å…³ï¼‰ã€**æ—¶æ•ˆæ€§**ï¼ˆæ˜¯å¦è¿‘æœŸï¼‰ã€**é‡è¦æ€§**ï¼ˆæ˜¯å¦å…³é”®ï¼‰ã€‚æ£€ç´¢å…¬å¼ï¼š

$$\text{Recall Score} = \alpha \cdot \text{Contextual Similarity} + \beta \cdot \text{Recency} + \gamma \cdot \text{Importance}$$

**ä¸‰ä¸ªç»´åº¦**ï¼š

1. **Contextual Similarityï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰**
   > ç¡®ä¿ä¸å½“å‰ä»»åŠ¡ç›¸å…³
   > - ä¾‹å¦‚ï¼šå½“å‰ä»»åŠ¡æ˜¯"æŸ¥è¯¢æ•°æ®åº“"ï¼Œä¼˜å…ˆå¬å›"æ•°æ®åº“ç›¸å…³"çš„è®°å¿†

2. **Recencyï¼ˆæ—¶æ•ˆæ€§ï¼‰**
   > è¿‘æœŸäº‹ä»¶æƒé‡æ›´é«˜
   > - ä¾‹å¦‚ï¼šæ˜¨å¤©çš„è®°å¿†æ¯”å»å¹´çš„è®°å¿†æ›´é‡è¦

3. **Importanceï¼ˆé‡è¦æ€§ï¼‰**
   > å…³é”®äº‹ä»¶ä¼˜å…ˆå¬å›
   > - ä¾‹å¦‚ï¼šåŒ…å«"é”™è¯¯"ã€"å¤±è´¥"çš„è®°å¿†æ›´é‡è¦

**å®ç°è¦ç‚¹**ï¼šç›¸ä¼¼åº¦ + æ—¶æ•ˆæ€§ + é‡è¦æ€§åŠ æƒã€‚ä»¥ä¸‹ä¸ºå¯é€‰å‚è€ƒå®ç°ï¼š

```python
# é«˜çº§æ£€ç´¢ç­–ç•¥ï¼ˆä¼ªä»£ç ï¼‰

class ContextualMemoryRetrieval:
    def __init__(self, vector_db, alpha=0.5, beta=0.3, gamma=0.2):
        self.vector_db = vector_db
        self.alpha = alpha  # ç›¸ä¼¼åº¦æƒé‡
        self.beta = beta    # æ—¶æ•ˆæ€§æƒé‡
        self.gamma = gamma  # é‡è¦æ€§æƒé‡
    
    def retrieve(self, query, top_k=5):
        """æ£€ç´¢ç›¸å…³è®°å¿†"""
        # 1. è¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢
        similar_memories = self.vector_db.similarity_search(query, top_k=top_k*2)
        
        # 2. è®¡ç®—ç»¼åˆå¾—åˆ†
        scored_memories = []
        for memory in similar_memories:
            # ç›¸ä¼¼åº¦å¾—åˆ†ï¼ˆ0-1ï¼‰
            similarity_score = memory["similarity"]
            
            # æ—¶æ•ˆæ€§å¾—åˆ†ï¼ˆ0-1ï¼‰ï¼šè¶Šæ–°å¾—åˆ†è¶Šé«˜
            recency_score = self.calculate_recency(memory["timestamp"])
            
            # é‡è¦æ€§å¾—åˆ†ï¼ˆ0-1ï¼‰
            importance_score = memory.get("importance", 0.5)
            
            # ç»¼åˆå¾—åˆ†
            final_score = (
                self.alpha * similarity_score +
                self.beta * recency_score +
                self.gamma * importance_score
            )
            
            scored_memories.append({
                "memory": memory,
                "score": final_score
            })
        
        # 3. æŒ‰å¾—åˆ†æ’åºï¼Œè¿”å› Top K
        scored_memories.sort(key=lambda x: x["score"], reverse=True)
        return [m["memory"] for m in scored_memories[:top_k]]
    
    def calculate_recency(self, timestamp):
        """è®¡ç®—æ—¶æ•ˆæ€§å¾—åˆ†"""
        import time
        current_time = time.time()
        age = current_time - timestamp  # å¹´é¾„ï¼ˆç§’ï¼‰
        
        # è¶Šæ–°å¾—åˆ†è¶Šé«˜ï¼ˆæŒ‡æ•°è¡°å‡ï¼‰
        # ä¾‹å¦‚ï¼š1 å°æ—¶å‰ = 0.9ï¼Œ1 å¤©å‰ = 0.5ï¼Œ1 å‘¨å‰ = 0.1
        decay_rate = 0.0001  # è¡°å‡ç‡
        return max(0, 1 - age * decay_rate)

# ä½¿ç”¨ç¤ºä¾‹
retrieval = ContextualMemoryRetrieval(vector_db=pinecone_db)

# æ£€ç´¢ç›¸å…³è®°å¿†
query = "æŸ¥è¯¢æ•°æ®åº“æ—¶é‡åˆ°äº†è¿æ¥é”™è¯¯"
memories = retrieval.retrieve(query, top_k=5)

# è¿”å›çš„è®°å¿†ä¼šç»¼åˆè€ƒè™‘ç›¸ä¼¼åº¦ã€æ—¶æ•ˆæ€§ã€é‡è¦æ€§
```

> ğŸ’¡ **å·¥ç¨‹å®è·µ**ï¼š
> - ç»“åˆå¤šç­–ç•¥æ’åºï¼Œæé«˜é•¿æœŸä»»åŠ¡çš„è®°å¿†ç²¾åº¦å’Œæ•ˆç‡
> - æ ¹æ®ä»»åŠ¡ç±»å‹è°ƒæ•´æƒé‡ï¼ˆå¦‚ï¼šå¯¹è¯ä»»åŠ¡æ›´é‡è§†æ—¶æ•ˆæ€§ï¼ŒçŸ¥è¯†ä»»åŠ¡æ›´é‡è§†ç›¸ä¼¼åº¦ï¼‰

---

## ğŸ”„ å››ã€è®°å¿†ç®¡ç†æ€»çº¿ï¼šä¿¡æ¯æµè½¬æœºåˆ¶

å®Œæ•´è®°å¿†ç³»ç»Ÿéœ€è¦ä¸€ä¸ª **Memory Stream** æ¥ç®¡ç†ä¿¡æ¯æµå…¥ä¸æµå‡ºã€‚

**ç®€å•ç†è§£**ï¼š
> å°±åƒå·¥å‚çš„ç”Ÿäº§çº¿ï¼š
> 1. **æ¥æ”¶**ï¼šæ¥æ”¶åŸææ–™ï¼ˆç”¨æˆ·è¾“å…¥ã€è§‚å¯Ÿç»“æœï¼‰
> 2. **å¤„ç†**ï¼šåŠ å·¥å¤„ç†ï¼ˆåˆ†å—ã€å‘é‡åŒ–ï¼‰
> 3. **å­˜å‚¨**ï¼šä¿å­˜åˆ°ä»“åº“ï¼ˆLTMï¼‰
> 4. **æ£€ç´¢**ï¼šéœ€è¦æ—¶ä»ä»“åº“å–å‡ºï¼ˆæ£€ç´¢ç›¸å…³è®°å¿†ï¼‰
> 5. **æ•´åˆ**ï¼šç»„è£…æˆæœ€ç»ˆäº§å“ï¼ˆPromptï¼‰

### 4.1 è®°å¿†ç®¡ç†æ€»çº¿çš„å››ä¸ªç»„ä»¶

#### 1. Perceiverï¼ˆæ„ŸçŸ¥å™¨ï¼‰

**ç®€å•ç†è§£**ï¼š
> å°±åƒ"ä¿¡æ¯æ¥æ”¶å™¨"ï¼Œæ¥æ”¶ç”¨æˆ·è¾“å…¥å’Œè§‚å¯Ÿç»“æœï¼Œè¿›è¡Œé¢„å¤„ç†ã€‚

**åŠŸèƒ½**ï¼š
> - é¢„å¤„ç†ç”¨æˆ·è¾“å…¥ä¸ Observation
> - è¿›è¡Œåˆ†å—ï¼ˆChunkingï¼‰
> - æå–å…³é”®ä¿¡æ¯

**ä»£ç ç¤ºä¾‹**ï¼š

```python
# Perceiverï¼ˆä¼ªä»£ç ï¼‰

class Perceiver:
    def process(self, user_input, observation):
        """å¤„ç†ç”¨æˆ·è¾“å…¥å’Œè§‚å¯Ÿç»“æœ"""
        # 1. åˆ†å—ï¼ˆå¦‚æœå†…å®¹å¤ªé•¿ï¼‰
        chunks = self.chunk_text(user_input + observation)
        
        # 2. æå–å…³é”®ä¿¡æ¯
        key_info = self.extract_key_info(chunks)
        
        return {
            "chunks": chunks,
            "key_info": key_info
        }
    
    def chunk_text(self, text, max_chunk_size=500):
        """æ–‡æœ¬åˆ†å—"""
        # ç®€å•çš„æŒ‰æ®µè½åˆ†å—ï¼ˆå®é™…åº”è¯¥ç”¨æ›´æ™ºèƒ½çš„æ–¹æ³•ï¼‰
        paragraphs = text.split('\n\n')
        chunks = []
        current_chunk = ""
        
        for para in paragraphs:
            if len(current_chunk) + len(para) <= max_chunk_size:
                current_chunk += para + "\n\n"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = para + "\n\n"
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
```

#### 2. Embedding Generatorï¼ˆå‘é‡ç”Ÿæˆå™¨ï¼‰

**ç®€å•ç†è§£**ï¼š
> å°±åƒ"ç¿»è¯‘å™¨"ï¼ŒæŠŠæ–‡æœ¬è½¬æ¢æˆå‘é‡ï¼ˆæ•°å­—ï¼‰ï¼Œæ–¹ä¾¿å­˜å‚¨å’Œæ£€ç´¢ã€‚

**åŠŸèƒ½**ï¼š
> - å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
> - å­˜å…¥ LTMï¼ˆå‘é‡æ•°æ®åº“ï¼‰

**ä»£ç ç¤ºä¾‹**ï¼š

```python
# Embedding Generatorï¼ˆä¼ªä»£ç ï¼‰

class EmbeddingGenerator:
    def __init__(self, embedding_model):
        self.embedding_model = embedding_model  # å¦‚ OpenAI Embeddings
    
    def generate_and_store(self, chunks, metadata):
        """ç”Ÿæˆå‘é‡å¹¶å­˜å‚¨åˆ° LTM"""
        vectors = []
        
        for chunk in chunks:
            # ç”Ÿæˆå‘é‡
            embedding = self.embedding_model.embed(chunk)
            
            # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            vector_db.add(
                vector=embedding,
                text=chunk,
                metadata=metadata
            )
            
            vectors.append(embedding)
        
        return vectors
```

#### 3. Retrieval Moduleï¼ˆæ£€ç´¢æ¨¡å—ï¼‰

**ç®€å•ç†è§£**ï¼š
> å°±åƒ"å›¾ä¹¦ç®¡ç†å‘˜"ï¼Œéœ€è¦æ—¶ä»ä»“åº“ï¼ˆLTMï¼‰æ‰¾åˆ°ç›¸å…³ä¹¦ç±ï¼ˆè®°å¿†ï¼‰ã€‚

**åŠŸèƒ½**ï¼š
> - Planner å¯åŠ¨å‰ï¼Œæ£€ç´¢ Top K è®°å¿†ç‰‡æ®µ
> - ä½¿ç”¨é«˜çº§æ£€ç´¢ç­–ç•¥ï¼ˆç›¸ä¼¼åº¦ + æ—¶æ•ˆæ€§ + é‡è¦æ€§ï¼‰

**ä»£ç ç¤ºä¾‹**ï¼š

```python
# Retrieval Moduleï¼ˆä¼ªä»£ç ï¼‰

class RetrievalModule:
    def __init__(self, retrieval_strategy):
        self.retrieval_strategy = retrieval_strategy  # ä½¿ç”¨é«˜çº§æ£€ç´¢ç­–ç•¥
    
    def retrieve(self, query, top_k=5):
        """æ£€ç´¢ç›¸å…³è®°å¿†"""
        # ä½¿ç”¨é«˜çº§æ£€ç´¢ç­–ç•¥ï¼ˆè§ 3.3 èŠ‚ï¼‰
        memories = self.retrieval_strategy.retrieve(query, top_k=top_k)
        return memories
```

#### 4. Context Refinerï¼ˆä¸Šä¸‹æ–‡ç²¾ç‚¼å™¨ï¼‰

**ç®€å•ç†è§£**ï¼š
> å°±åƒ"ç¼–è¾‘"ï¼ŒæŠŠå„ç§ä¿¡æ¯æ•´åˆæˆä¸€ç¯‡å¥½æ–‡ç« ï¼ˆPromptï¼‰ã€‚

**åŠŸèƒ½**ï¼š
> - æ•´åˆ STM æ‘˜è¦ã€LTM æ£€ç´¢ç»“æœåŠå½“å‰è¾“å…¥
> - å½¢æˆé«˜æ•ˆ Prompt æ³¨å…¥ LLM Planner
> - é˜²æ­¢"ä¸Šä¸‹æ–‡æ±¡æŸ“"
> - æå‡ LLM æ¨ç†æ•ˆç‡

**ä»£ç ç¤ºä¾‹**ï¼š

```python
# Context Refinerï¼ˆä¼ªä»£ç ï¼‰

class ContextRefiner:
    def refine(self, stm_summary, ltm_memories, current_input):
        """æ•´åˆä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆé«˜æ•ˆ Prompt"""
        # 1. æ•´åˆ STM æ‘˜è¦
        context_parts = []
        if stm_summary:
            context_parts.append(f"è¿‘æœŸæ‘˜è¦ï¼š\n{stm_summary}")
        
        # 2. æ•´åˆ LTM æ£€ç´¢ç»“æœ
        if ltm_memories:
            memory_text = "\n".join([
                f"- {m['text']}" for m in ltm_memories
            ])
            context_parts.append(f"ç›¸å…³å†å²ï¼š\n{memory_text}")
        
        # 3. æ·»åŠ å½“å‰è¾“å…¥
        context_parts.append(f"å½“å‰ä»»åŠ¡ï¼š\n{current_input}")
        
        # 4. ç»„åˆæˆå®Œæ•´ Prompt
        prompt = "\n\n".join(context_parts)
        
        return prompt
```

### 4.2 å®Œæ•´çš„ä¿¡æ¯æµè½¬æµç¨‹

**æµç¨‹å›¾**ï¼š

```
ç”¨æˆ·è¾“å…¥
   â†“
Perceiverï¼ˆæ„ŸçŸ¥å™¨ï¼‰
   â†“ åˆ†å—ã€æå–å…³é”®ä¿¡æ¯
Embedding Generatorï¼ˆå‘é‡ç”Ÿæˆå™¨ï¼‰
   â†“ ç”Ÿæˆå‘é‡
LTM Storageï¼ˆé•¿æœŸè®°å¿†å­˜å‚¨ï¼‰
   â†“
Retrieval Moduleï¼ˆæ£€ç´¢æ¨¡å—ï¼‰
   â†“ æ£€ç´¢ç›¸å…³è®°å¿†
Context Refinerï¼ˆä¸Šä¸‹æ–‡ç²¾ç‚¼å™¨ï¼‰
   â†“ æ•´åˆä¸Šä¸‹æ–‡
LLM Plannerï¼ˆå†³ç­–å¼•æ“ï¼‰
   â†“ ç”Ÿæˆ Thought å’Œ Action
æ‰§è¡Œå·¥å…·
   â†“ è·å– Observation
å›åˆ° Perceiverï¼ˆå¾ªç¯ï¼‰
```

**ä»£ç ç¤ºä¾‹ï¼ˆå®Œæ•´æµç¨‹ï¼‰**ï¼š

```python
# å®Œæ•´çš„è®°å¿†ç®¡ç†æ€»çº¿ï¼ˆä¼ªä»£ç ï¼‰

class MemoryBus:
    def __init__(self, stm, ltm, perceiver, embedding_gen, retrieval, refiner):
        self.stm = stm  # çŸ­æœŸè®°å¿†
        self.ltm = ltm  # é•¿æœŸè®°å¿†
        self.perceiver = perceiver
        self.embedding_gen = embedding_gen
        self.retrieval = retrieval
        self.refiner = refiner
    
    def process(self, user_input, observation):
        """å¤„ç†ç”¨æˆ·è¾“å…¥å’Œè§‚å¯Ÿç»“æœ"""
        # 1. Perceiverï¼šé¢„å¤„ç†
        processed = self.perceiver.process(user_input, observation)
        
        # 2. Embedding Generatorï¼šç”Ÿæˆå‘é‡å¹¶å­˜å‚¨
        self.embedding_gen.generate_and_store(
            processed["chunks"],
            metadata={"timestamp": time.time()}
        )
        
        # 3. æ·»åŠ åˆ° STM
        self.stm.add(
            thought="",
            action="",
            observation=observation
        )
        
        # 4. Retrievalï¼šæ£€ç´¢ç›¸å…³è®°å¿†
        query = user_input + observation
        ltm_memories = self.retrieval.retrieve(query, top_k=5)
        
        # 5. Context Refinerï¼šæ•´åˆä¸Šä¸‹æ–‡
        stm_summary = self.stm.get_summary()
        prompt = self.refiner.refine(stm_summary, ltm_memories, user_input)
        
        return prompt

# ä½¿ç”¨ç¤ºä¾‹
memory_bus = MemoryBus(
    stm=SummarizedMemory(),
    ltm=vector_db,
    perceiver=Perceiver(),
    embedding_gen=EmbeddingGenerator(),
    retrieval=RetrievalModule(),
    refiner=ContextRefiner()
)

# å¤„ç†ç”¨æˆ·è¾“å…¥
prompt = memory_bus.process(
    user_input="æŸ¥è¯¢ç”¨æˆ·æ•°æ®",
    observation="æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› 1000 æ¡è®°å½•"
)

# prompt åŒ…å«äº† STM æ‘˜è¦ã€LTM æ£€ç´¢ç»“æœã€å½“å‰è¾“å…¥
# å¯ä»¥å‘é€ç»™ LLM Planner äº†
```

> ğŸ’¡ **å…³é”®ç†è§£**ï¼š
> - **Perceiver**ï¼šæ¥æ”¶å’Œé¢„å¤„ç†ä¿¡æ¯
> - **Embedding Generator**ï¼šæŠŠæ–‡æœ¬è½¬æ¢æˆå‘é‡
> - **Retrieval Module**ï¼šä» LTM æ£€ç´¢ç›¸å…³è®°å¿†
> - **Context Refiner**ï¼šæ•´åˆæ‰€æœ‰ä¿¡æ¯ï¼Œç”Ÿæˆé«˜æ•ˆ Prompt
> 
> å››ä¸ªç»„ä»¶åä½œï¼Œå®ç°å®Œæ•´çš„è®°å¿†ç®¡ç†æµç¨‹ã€‚

---

## ğŸ” æ€»ç»“ï¼šAgent çš„è®°å¿†æ˜¯è‡ªä¸»æ€§çš„è½½ä½“

### ğŸ’¡ å¿«é€Ÿå›é¡¾ï¼šä½ å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ

1. **åˆ†å±‚è®°å¿†æ¶æ„**ï¼šSTMï¼ˆçŸ­æœŸè®°å¿†ï¼‰ã€LTMï¼ˆé•¿æœŸè®°å¿†ï¼‰ã€ExMï¼ˆå¤–éƒ¨çŸ¥è¯†ï¼‰
2. **çŸ­æœŸè®°å¿†ç®¡ç†**ï¼šæ»‘åŠ¨çª—å£ã€å¯¹è¯æ‘˜è¦ã€é‡è¦æ€§å‰ªæ
3. **é•¿æœŸè®°å¿†å­˜å‚¨**ï¼šå‘é‡æ•°æ®åº“ã€çŸ¥è¯†å›¾è°±ã€å…³ç³»å‹æ•°æ®åº“
4. **é«˜çº§æ£€ç´¢ç­–ç•¥**ï¼šç»¼åˆè€ƒè™‘ç›¸ä¼¼åº¦ã€æ—¶æ•ˆæ€§ã€é‡è¦æ€§
5. **è®°å¿†ç®¡ç†æ€»çº¿**ï¼šPerceiver â†’ Embedding â†’ Storage â†’ Retrieval â†’ Refiner

### ä¸‰å±‚è®°å¿†çš„æ ¸å¿ƒä½œç”¨

| å±‚æ¬¡ | ä½œç”¨ | ç®€å•ç†è§£ |
|------|------|---------|
| **STM** | ä¿è¯å½“å‰ä»»åŠ¡çš„å³æ—¶è¿è´¯ | è®°ä½å½“å‰æ­£åœ¨åšçš„äº‹æƒ… |
| **LTM** | æŒä¹…åŒ–ç»éªŒï¼Œæ”¯æŒè·¨ä»»åŠ¡å­¦ä¹  | ä¿å­˜è¿‡å»çš„é‡è¦ç»å† |
| **ExM** | æä¾›äº‹å®æ€§ä¸ä¸“ä¸šçŸ¥è¯† | éœ€è¦æ—¶æŸ¥é˜…èµ„æ–™ |

### å…³é”®è®¾è®¡åŸåˆ™

1. **æ™ºèƒ½é—å¿˜**ï¼šä¸æ˜¯è®°ä½æ‰€æœ‰ä¿¡æ¯ï¼Œè€Œæ˜¯è®°ä½é‡è¦çš„ï¼Œå¿˜è®°ä¸é‡è¦çš„
2. **é«˜æ•ˆæ£€ç´¢**ï¼šä¸æ˜¯ç®€å•å­˜å‚¨ï¼Œè€Œæ˜¯èƒ½å¤Ÿå¿«é€Ÿæ‰¾åˆ°ç›¸å…³ä¿¡æ¯
3. **åˆ†å±‚ç®¡ç†**ï¼šä¸æ˜¯å•ä¸€å­˜å‚¨ï¼Œè€Œæ˜¯åˆ†å±‚å­˜å‚¨ï¼Œå„å¸å…¶èŒ
4. **åŠ¨æ€æ›´æ–°**ï¼šä¸æ˜¯é™æ€å­˜å‚¨ï¼Œè€Œæ˜¯åŠ¨æ€æ›´æ–°ï¼Œä¿æŒæ—¶æ•ˆæ€§

### å®æˆ˜å»ºè®®

1. **ä»ç®€å•å¼€å§‹**ï¼šå…ˆå®ç°æ»‘åŠ¨çª—å£ï¼Œå†é€æ­¥ä¼˜åŒ–
2. **é€‰æ‹©åˆé€‚çš„å­˜å‚¨**ï¼šæ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©å­˜å‚¨ä»‹è´¨
3. **ä¼˜åŒ–æ£€ç´¢ç­–ç•¥**ï¼šæ ¹æ®ä»»åŠ¡ç±»å‹è°ƒæ•´æ£€ç´¢æƒé‡
4. **ç›‘æ§è®°å¿†è´¨é‡**ï¼šå®šæœŸæ£€æŸ¥è®°å¿†çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§

> ğŸ’¡ **æ ¸å¿ƒç†è§£**ï¼š
> ä¸€ä¸ªä¼˜ç§€çš„ Agent å·¥ç¨‹å¸ˆï¼Œä¸ä»…è¦è®© Agent **è®°ä½é‡è¦ä¿¡æ¯**ï¼Œæ›´è¦è®©å®ƒ **æ™ºèƒ½é—å¿˜**ï¼Œç²¾å‡†å¬å›é«˜ä»·å€¼è®°å¿†ï¼Œå®ç°é•¿æœŸè‡ªä¸»æ€§ã€‚
> 
> è®°å¿†ç®¡ç†ä¸æ˜¯ç®€å•çš„å­˜å‚¨å’Œæ£€ç´¢ï¼Œè€Œæ˜¯ä¸€å¥—å®Œæ•´çš„å·¥ç¨‹åŒ–ç³»ç»Ÿï¼Œéœ€è¦ç»¼åˆè€ƒè™‘å­˜å‚¨ã€æ£€ç´¢ã€å‹ç¼©ã€æ›´æ–°ç­‰å¤šä¸ªç»´åº¦ã€‚

---

## ğŸ“š å»¶ä¼¸é˜…è¯»ï¼ˆå«å¯ç›´æ¥è®¿é—®é“¾æ¥ï¼‰

ä»¥ä¸‹èµ„æºæŒ‰ä¸»é¢˜åˆ†ç±»ï¼Œæ¯ä¸ªèµ„æºéƒ½é™„æœ‰ç®€è¦è¯´æ˜ï¼Œå¸®åŠ©ä½ é€‰æ‹©åˆé€‚çš„å­¦ä¹ ææ–™ã€‚

### ğŸ§  åˆ†å±‚è®°å¿†æ¶æ„

* [**Agent Memory Architecture, Layered Memory Modelï¼ˆåˆ†å±‚è®°å¿†æ¨¡å‹è®ºæ–‡ï¼‰**](https://arxiv.org/abs/2304.12213)ï¼šAgent åˆ†å±‚è®°å¿†æ¶æ„çš„å¼€åˆ›æ€§è®ºæ–‡ã€‚**å¿…è¯»è®ºæ–‡**ï¼Œé€‚åˆæ‰€æœ‰è¯»è€…ã€‚

* [**Generative Agents: Interactive Simulacra of Human Behaviorï¼ˆç”Ÿæˆå¼ Agent è®ºæ–‡ï¼‰**](https://arxiv.org/abs/2304.03442)ï¼šStanford 2023 å¹´çš„ç»å…¸è®ºæ–‡ï¼Œå±•ç¤ºäº†å¦‚ä½•å®ç°å…·æœ‰è®°å¿†çš„ Agentã€‚**å¼ºçƒˆæ¨è**ï¼Œé€‚åˆæƒ³äº†è§£è®°å¿†ç®¡ç†å®è·µçš„è¯»è€…ã€‚

### ğŸ” è®°å¿†æ£€ç´¢ç­–ç•¥

* [**Contextual Memory Retrieval, Recency & Importance Weighted Searchï¼ˆLlamaIndex è®°å¿†æ£€ç´¢ï¼‰**](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/memory/)ï¼šLlamaIndex çš„è®°å¿†æ£€ç´¢å®ç°ï¼ŒåŒ…å«æ—¶æ•ˆæ€§å’Œé‡è¦æ€§åŠ æƒæœç´¢ã€‚**å¼ºçƒˆæ¨è**ï¼Œé€‚åˆä½¿ç”¨ LlamaIndex çš„å¼€å‘è€…ã€‚

* [**LangChain Memory Managementï¼ˆLangChain è®°å¿†ç®¡ç†ï¼‰**](https://python.langchain.com/docs/modules/memory/)ï¼šLangChain çš„è®°å¿†ç®¡ç†å®ç°ï¼ŒåŒ…å«å¤šç§è®°å¿†ç±»å‹ã€‚é€‚åˆä½¿ç”¨ LangChain çš„å¼€å‘è€…ã€‚

### ğŸ—„ï¸ å­˜å‚¨ä»‹è´¨

* [**Pinecone Vector Databaseï¼ˆPinecone å‘é‡æ•°æ®åº“ï¼‰**](https://www.pinecone.io/)ï¼šæµè¡Œçš„å‘é‡æ•°æ®åº“æœåŠ¡ã€‚é€‚åˆéœ€è¦å‘é‡å­˜å‚¨çš„å¼€å‘è€…ã€‚

* [**Neo4j Knowledge Graphï¼ˆNeo4j çŸ¥è¯†å›¾è°±ï¼‰**](https://neo4j.com/)ï¼šæµè¡Œçš„çŸ¥è¯†å›¾è°±æ•°æ®åº“ã€‚é€‚åˆéœ€è¦å…³ç³»å­˜å‚¨çš„å¼€å‘è€…ã€‚

* [**Knowledge Graph for LLM Agent Reasoningï¼ˆçŸ¥è¯†å›¾è°±åœ¨ Agent ä¸­çš„åº”ç”¨ï¼‰**](https://neo4j.com/blog/knowledge-graphs-for-llms/)ï¼šçŸ¥è¯†å›¾è°±åœ¨ LLM Agent ä¸­çš„åº”ç”¨æŒ‡å—ã€‚é€‚åˆæƒ³äº†è§£çŸ¥è¯†å›¾è°±çš„è¯»è€…ã€‚

### ğŸ”„ è®°å¿†ç®¡ç†å®è·µ

* [**Memory Management Best Practicesï¼ˆè®°å¿†ç®¡ç†æœ€ä½³å®è·µï¼‰**](https://www.promptingguide.ai/techniques/memory)ï¼šè®°å¿†ç®¡ç†çš„æœ€ä½³å®è·µæŒ‡å—ã€‚é€‚åˆæƒ³ä¼˜åŒ–è®°å¿†ç³»ç»Ÿçš„å¼€å‘è€…ã€‚

* [**Context Window Optimizationï¼ˆä¸Šä¸‹æ–‡çª—å£ä¼˜åŒ–ï¼‰**](https://www.anthropic.com/research/more-context)ï¼šä¸Šä¸‹æ–‡çª—å£ä¼˜åŒ–çš„ç ”ç©¶ã€‚é€‚åˆæƒ³ä¼˜åŒ– Context Window çš„å¼€å‘è€…ã€‚

---

## ğŸ”” ç³»åˆ—è¯´æ˜

> æœ¬æ–‡æ˜¯[ã€ŠğŸ§  LLM/Agent ä»å…¥é—¨åˆ°ç²¾é€šï¼šå‘Šåˆ«æµ…å°è¾„æ­¢ã€‹](/categories/ğŸ§ -LLM-Agent-ä»å…¥é—¨åˆ°ç²¾é€šï¼šå‘Šåˆ«æµ…å°è¾„æ­¢/)ç³»åˆ—ç¬¬ 9 ç¯‡ã€‚ä¸Šä¸€ç¯‡ï¼š[å¤æ‚ä»»åŠ¡ Agent æ€ä¹ˆæ‹†ï¼Ÿä»»åŠ¡è§„åˆ’ä¸ Self-Correction](/2025-12-19-llm-agent-task-planning/)ã€‚ä¸‹ä¸€ç¯‡ï¼š[LangChainã€LlamaIndexã€AutoGPT æ€ä¹ˆé€‰ï¼ŸAgent æ¡†æ¶å¯¹æ¯”](/2025-12-20-llm-agent-framework-comparison/)ã€‚

